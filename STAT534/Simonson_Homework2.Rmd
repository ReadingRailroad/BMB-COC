---
title: "Ecostats Homework 2"
author: "Martin Simonson"
date: "October 18, 2019"
output: pdf_document
editor_options: 
  chunk_output_type: console
---



```{r,include=F}
# Front matter
rm(list=ls())  # removes objects from environment

# Function to load and install packages
packages<-function(x, repos="http://cran.r-project.org", ...){
x<-as.character(match.call()[[2]])
if (!require(x,character.only=TRUE)){
install.packages(pkgs=x, repos=repos, ...)
require(x,character.only=TRUE)
}
}

# Setting Working Directory
setwd("C:/Users/martysim/Documents/BMB-COC/STAT534/")

# setting up packages
packages(ggplot2)
packages(RMark)
packages(gtools)
```

# 1.) Deer Mice

These data come from a study of deer mice population in sagebrush steppe in Utah. Individuals were trapped on 5 nights. The usual notation for classical (Otis) closed population models is:

- $t$: The number of trapping occasions
- $n$: number of individuals caught on each trapping occasion (vector of length t)
- $n.$: (ndot) the total number of captures, $n. = \Sigma_{i=1}^t n_i$
- $M$: number of tags in popoulation just prior to occasion _i_, $M_i = \Sigma_{j=1}^{i-1}u_j$ except $M_1 = 0$
- $M.$: (Mdot) $=\Sigma_{i=1}^t M_i$ Note this does not include $M_t+1$
- $M_{t+1}$: Total number of unique individuals seen
- $u$: number of unmarked individuals caught on each occasion (vector of length t)
- $m$: number of marked individuals caught on each occasion (vector of length t)
- $m.$ (mdot) total captures of marked individuals, $m. = \Sigma_{i=1}^t m_i$

Note that $n_i = u_i+m_i$ for all $i$. Summary statistics for the mark-recapture study of deer mice are:

              Trap Night 1     Trap Night 2       Trap Night 3    Trap Night 4    Trap Night 5
----------    --------------   ----------------   -------------   -------------   --------------
$n_i$         14               9                  12              11              10
$u_i$         14               5                  11              7               5
$m_i$         0                4                  1               4               5
$M_i$         0                14                 19              30              37  
----------    -------------   ----------------    -------------   -------------   --------------

and $M_{t+1} = 42$. The Chao and Huggins reading has the summary-statistics version of the log-likelihood function for the $M_t$ model. Dr. Dixon's R function to compute the log likelihood is:

```{r}
lnlMt <- function(param, data) {
  t <- data[1] # see note below
  Mt1 <- data[2]
  n <- data[-c(1:2)]
  N <- param[1] # see note below
  p <- param[-1]
  
  lfactorial(N) - lfactorial(N-Mt1) + sum(n*log(p)) + sum((N-n)*log(1-p))
}
```

'param' is a vector with t+1 parameters: N followed by the t capture probabilities. 'data' is a vector with t+2 values: # capture occasions, Mt+1, followed by t occasion-specific # captured.

## (a)

Using results from fitting model $M_t$, calculate a Wald 95% confidence interval for $\hat{N}$

```{r}
data<-c(5, 42, 14, 9, 12, 11, 10)
param<-c(42, rep(0.6,5))

fit.1a<-optim(param, lnlMt, method = 'BFGS',data = data, control = list(fnscale = -1), hessian = T)
fit.1a$par


betahat<-fit.1a$par
fit.1a.vc<-solve(-fit.1a$hessian)
fit.1a.se<-sqrt(diag(fit.1a.vc))

betahat.ci<-cbind(
  lower = betahat - qnorm(0.975)*fit.1a.se,
  upper = betahat + qnorm(0.975)*fit.1a.se)
betahat.ci[1,]
```

Our estimate of N is 75.45, and our 95% confidence interval is bounded between 46.80 and 104.10.

## (b)

Rewrite the log-likelhiood function in terms of $log(N)$. Use log-transformed $N$ to calculate a Wald 95% confidence interval for $N$.

```{r}

data<- c(5, 42, 14, 9, 12, 11, 10)
param<-c(log(42), rep(0.1,5))

lnlMt2 <- function(param, data) {
  t <- data[1] 
  Mt1 <- data[2]
  n <- data[-c(1:2)]
  logN <- exp(param[1]) 
  p <- param[-1]
  
  lfactorial(logN) - lfactorial(logN-Mt1) + sum(n*log(p)) + sum((logN-n)*log(1-p))
}


fit.1b<-optim(param, 
              lnlMt2, 
              method = 'BFGS',
              data = data, 
              control = list(fnscale = -1),
              hessian = T)
fit.1b$par
exp(fit.1b$par[1])

betahat<-fit.1b$par[1]
fit.1b.vc<-solve(-fit.1b$hessian)
fit.1b.se<-sqrt(diag(fit.1b.vc))

betahat.ci<-cbind(
  lower = betahat - qnorm(0.975)*fit.1b.se,
  upper = betahat + qnorm(0.975)*fit.1b.se)
exp(betahat.ci[1,])
```

The estimate for log-transformation yielded an estimate of $N = 75.43$ and the 95% confidence interval is bounded between 51.60 and 110.25.


## (c)

Write a profile log-likelihood function for $N$ (so the only parameter is $\hat{N}$, $p$ is computed in your function). Use that model to calculate a 95% profile confidence interval for $\hat{N}$. 

```{r}
# need to re-structure data vector to fit this function?
data<- c(5, 42, 14, 9, 12, 11, 10)
param<-c(75.42819, rep(0.3,5))

lnlM0p <- function(param, data) {
   N <- param[1]
  # overall probability of capture is # seen / N*#times
   p <- data[-c(1:2)]/(N)
  # then call lnlMt with the provided N and calculated p
   lnlMt(c(N,p), data)
  }


# maximize the fit in 1D
optimize(lnlM0p, c(20,120), data=data, maximum=T)
# arguments are the:
#   function to maximize, first argument must be the parameter
#   the interval to search.  Could also be lower=40, upper=100
#   any additional arguments to the function, here the data
#   default is to minimize, setting maximum=T looks for the maximum
# gives you $maximum = location of maximum and $objective = lnl at max
# generate values for the profile likelihood curve


# finding a 95% confidence interval
# approach: want to find X values such that 2*(lnl(mle) - lnl(X)) = 3.84
#  do by finding roots of (lnl(mle) - lnl(X)) - 3.84/2 = 0

# implement by defining a check function to calculate (lnl(X) - lnl(mle)) + 3.84
# that's the negative, but this has the same roots, and matches shape of lnlN

ciM0p <- function(X, mle, data, coverage = 0.95) {
#  X is the argument
#  mle is the estimated parameter
#  coverage is the desired coverage, e.g. 0.95, 
#    used to calculate the Chi-square quantile, e.g. 3.84
#  and data is the capture history matrix

  (lnlM0p(X, data=data) - lnlM0p(mle, data=data)) + qchisq(coverage,1)/2
  }

mleN <- optimize(lnlM0p, c(20,100), data=data, maximum=T)$maximum
mleN

lowerN <- uniroot(ciM0p, c(20, mleN), mle=mleN, data=data)
# first argument is the function to find a root for
# second is the interval to search in
# since ciM0p requires an mle for N and a data set, 
#   need to provide those by name in the call to uniroot

lowerN$root
# $root is the root, the rest is supplemental information

# find upper ci endpoint by searching from mle to something large

upperN <- uniroot(ciM0p, c(mleN, mleN*10), mle=mleN, data=data)
upperN$root

cat('95% ci')
c(lowerN$root, upperN$root)

# and if you don't like fractions of critters, 
#   round lower down and upper up

#c(floor(lowerN$root), ceiling(upperN$root) )

```

The profile log-likelihood for $N$ results in a 95% confidence interval between 54.97 and 118.36.


## (d)

Look at the plots of profile likelihood vs. $N$ and vs. $log(N)$. If you had to use a normal approximation, which is more appropriate? $N \approx normal$ or $log(N) \approx normal$? Briefly explain your choice and include your plot(or plots) of the profile likelihood.

```{r}
# profile likelihood function
allN <- 20:120
lnlN<-rep(NA,length(allN))
for(i in 1:length(allN)){
  lnlN[i] <-lnlM0p(allN[i], data)
}
```

```{r}
plot.new() # clear previous plots
par(mfrow=c(1,2)) # set frame to show two plots at once, side by side
par(mar=c(3,3,3,3)+0.2, mgp=c(2,0.8,0)) # setting margins, etc

plot(allN,lnlN, main = "Profile likelihood vs. N")

plot(allN,lnlN, main = "Profile likelihood vs. log(N)", log = "x")
```

Although neither plot shows very strong evidence for a normal approximation, the $log(n) \approx normal$ would be better for analysis, due to a more distinct parabola shape.


## (e)

Results from fitting 3 models ($M_0, M_t, M_b$) are:

Model         AIC              $\hat{N}$        s.e.  
----------    --------------   ---------------  -------------
$M_0$         -13.51           75.88            14.77 
$M_t$         -7.05            75.40            14.59  
$M_b$         -11.90           61.65            17.67
----------    -------------    ---------------  -------------

Using AIC weights, compute the model-averaged estimate of $N$ and its standard error, using the Buckland s.e. formula. Derive the AIC weights from AIC column. Variance needed in Buckland formula is the variance($\hat{N}$). Standard deviation is of observations, and standard error is of the estimate. Variance of observations and variance of estimate, in this problem we want to square the s.e. column to get the variance of the estimate. Fun fact: there is another distinction between sd and se, that is, se is an estimated variance of an estimate.

```{r}
M0.AIC<- -13.51
Mt.AIC<- -7.05
Mb.AIC<- -11.90

M0.Delta.AIC<-1
mt.Delta.AIC<-exp(-6.46/2)
mb.Delta.AIC<-exp(-1.61/2)

AIC.sums<-sum(M0.Delta.AIC,mt.Delta.AIC,mb.Delta.AIC)

M0.w<-M0.Delta.AIC/AIC.sums
Mt.w<-mt.Delta.AIC/AIC.sums
Mb.w<-mb.Delta.AIC/AIC.sums

M0.v<-14.77^2
Mt.v<-14.59^2
Mb.v<-17.67^2

v.sums<-sum(M0.v,Mt.v,Mb.v)

theta<-(M0.w*75.88)+(Mt.w*75.40)+(Mb.w*61.65)
theta

SE<- (M0.w*(sqrt(M0.v+(75.88-theta)^2)))+(Mt.w*(sqrt(Mt.v+(75.4-theta)^2)))+(Mb.w*(sqrt(Mb.v+(61.65-theta)^2)))
SE


```

The model-averaged estimate of $\hat{N} = 71.59$ and the model-averaged $SE = 16.84$.

## (f)

Imagine you had three different studies of the same population. These are conducted by different people at slightly different times, but we will assume that the population remains closed across the three studies (so the true $N$ is the same for all three studies). The study results are:

Study         $\hat{N}$        Var $\hat{N}$  
----------    --------------   --------------
A             145              30         
B             147              30           
C             143              30         
----------    -------------    --------------

The three studies can be assumed to be independent estimates of $N$. If you average the results from these three studies, what is the pooled estimate ($\hat{N}$) and its associated standard error? _Note:_ These three studies are independent, so averaging them is just like calculating a sample mean and its precision.

```{r}
Nhat<- mean(145,147,143)
Nhat

study<-c(145,147,143)
error<- sd(study)/sqrt(3)
error
```

The pooled estimate of $\hat{N} = 145$ and its associated standard error is $SE = 1.1547$.

## (g)

Now imagine the same results were obtained form fitting three models to the results in from Study A. Those results, including model weights, are:

Model         $\hat{N}$        Var $\hat{N}$    Weight  
----------    --------------   ---------------  -------------
A             145              30               1/3
B             147              30               1/3  
C             143              30               1/3
----------    -------------    ---------------  -------------

Compute the model-averaged estimate of $N$ and its standard error (Buckland formula is sufficient).

```{r}
MA.w<-1/3
MB.w<-1/3
MC.w<-1/3

MA.v<-30
MB.v<-30
MC.v<-30


theta<-(MA.w*145)+(MB.w*147)+(MC.w*143)
theta

SE<- (MA.w*(sqrt(MA.v+(145-theta)^2)))+(MB.w*(sqrt(MB.v+(147-theta)^2)))+(MC.w*(sqrt(MC.v+(143-theta)^2)))
SE
```

Our estimate of $\hat{N} = 145$, which is the same as the pooled estimate in (f). The Buckland standard error formula yielded $SE=5.713$

## (h)

In statistical terms, why are the results from question 1(g) not identical to those from question 1(f)? Note that at least some of the values should be different.

- __Answer:__ The estimate of $\hat{N}$ is the same between question 1(g) and 1(f), but that makes since because the mean of our three estimates is the sum of each estimate divided by three, while the weighted model average method had equal model weights of 1/3, which yielded the same estimate. Our estimates of precision were different, however. This difference is due to the fact that in part 1(f), we are measuring the variance of $\hat{N}$ estimates, ignoring the variance within the models. In 1(g) however, we used the Buckland formula which accounts for the within-model variance and more appropriately provides estimates of precision around $\hat{N}$.

# 2.) Heterogeneity Models

This problem explores models for heterogeneity. The data in _huggins2019.txt_ have capture histories for 97 animals and a measured covariate for each animal. The data are simulated and true population size will be shared by Dr. Dixon later.

## (a)
  
Fit a variety of models including some that model heterogeneity using a mixture distribution (i.e. the Pledger approach) to the data. What model(s) seem reasonable? Do the data support heterogeneity between individuals? _Note:_ Dr. Dixon has ahad trouble using the 'HetClosed' for some models, so using the 'HetFull' class. Dr. Dixon will distribute an Intro to modeling heterogeneity guide.

```{r}
huggins<-import.chdata("huggins2019.txt")
head(huggins)
```

```{r,}
# models:
run.huggins <- function() {
  f0 <- list(formula=~1)
  f0s<- list(formula = ~1, share = TRUE) # shared probability of capture and recapture
  ft <- list(formula=~time, share = T)
  fT <- list(formula = ~ Time, share = T)
  ftb<- list(formula = ~ time+c, share = T)
  fh<-list(formula=~mixture, share = T) # all 8 models
  fht<-list(formula=~mixture+time, share = T) # hetreogeneity model + time effect
  fbh <- list(formula =~mixture+c, share = T) # c = capture probability
  fbht<-list(formula=~mixture+time+c, share = T)
  
  
  
  m0 <-mark(huggins, model='FullHet', model.parameters = list(p=f0s))
  mt <-mark(huggins, model='FullHet', model.parameters = list(p=ft))
  mT <-mark(huggins, model='FullHet', model.parameters = list(p=fT))
  mb <-mark(huggins, model='FullHet', model.parameters = list(p=f0,c=f0))
  mtb <-mark(huggins, model='FullHet', model.parameters = list(p=ftb, c=f0))
  mh <-mark(huggins, model='FullHet', model.parameters = list(p=fh))
  mht<-mark(huggins,model='FullHet', model.parameters=list(p=fht))
  mbh<-mark(huggins,model='FullHet', model.parameters=list(p=fbh,c=f0))
  mbht<-mark(huggins,model='FullHet',model.parameters=list(p=fbht,c=f0))
  
  return(collect.models)
}

huggins.models<-run.huggins()
```

```{r,}

model.table(huggins.models,model.name=F)
```

```{r}

```

```{r}

```

## (b)

Fit a variety of models to the data, including some that model heterogenity as a function of the covariate X (i.e. the Huggins approach). What model(s) seem reasonable? Do the data support heterogeneity between individuals?
```{r}
run.huggins2 <- function() {
  f0 <- list(formula=~1)
  f0s<- list(formula = ~1, share = TRUE) # shared probability of capture and recapture
  ft <- list(formula=~time, share = T)
  fT <- list(formula = ~ Time, share = T)
  ftb<- list(formula = ~ time+c, share = T)
  fc<-list(formula=~X, share = T) # all 8 models
  fct<-list(formula=~X+time, share = T) # hetreogeneity model + time effect
  fbc <- list(formula =~X+c, share = T) # c = capture probability
  fbct<-list(formula=~X+time+c, share = T)
  
  
  
  m0 <-mark(huggins, model='Huggins', model.parameters = list(p=f0s))
  mt <-mark(huggins, model='Huggins', model.parameters = list(p=ft))
  mT <-mark(huggins, model='Huggins', model.parameters = list(p=fT))
  mb <-mark(huggins, model='Huggins', model.parameters = list(p=f0,c=f0))
  mtb <-mark(huggins, model='Huggins', model.parameters = list(p=ftb, c=f0))
  mc <-mark(huggins, model='Huggins', model.parameters = list(p=fc))
  mct<-mark(huggins,model='Huggins', model.parameters=list(p=fct))
  mbc<-mark(huggins,model='Huggins', model.parameters=list(p=fbc,c=f0))
  mbct<-mark(huggins,model='Huggins',model.parameters=list(p=fbct,c=f0))
  
  return(collect.models)
}

huggins.models2<-run.huggins2()
```

```{r}

```

## (c)

How might you evaluate which of these two approaches is more reasonable for these data? _Note:_ This is a "think about what you have available" question. Likelihood __cannot__ be used because the Pledger and Huggins approaches are based on different data sets.

- __Answer:__

## (d)

The annual report needs to make a statement about the number of individuals in this population. This will be read by the general public and legislators, so it needs to be succinct. What conclusions can be made?

- __Answer:__

# 3.) Bats

This problem is a simplified version of something in regular use. Wind turbines kill birds and bats. The Fish and Wildlife Service cares (a lot) when those are endangered or threatened bats (because of the Endangered Species Act) or eagles (because of the Bald and Golden Eagle Protection Act). Hence, owners of wind turbine farms are required to estimate the number of killed bats and killed eagles. Eagle kill is mostly in the winter and an eagle carcass on snow is pretty easy to spot. Bat mortality is harder to estimate. Bat kill is mostly late summer and early fall. Dead bats are hard to spot; they are small, dark brown critters that fall on bare ground, grass/prairie, or in the middle of a crop field. The data to estimate bat kill are collected by trained technicians who search the ground around each turbine and identify each carcass they find. They search every week and sometimes more frequently. The number killed is larger than the number seen for three different reasons:

- only a portion of the area is searched
- scavengers, e.g. coyotes or raccoons, remove a carcass before the technician looks for it
- the searcher doesn’t see a carcass that is in the search area and not scavenged.

The portion of area searched, $\pi_a$, is a known constant. The searcher efficiency and scavenger removal rate are estimated by placing a known number of marked dead bats on the ground and seeing how many are found by the technician. In actual use, the searcher efficiency and scavenger removal rate are estimated by two different studies. I am simplifying this problem by combining the two rates into a single probability: $\pi_s$ is the probability that a carcass falling in the searched area is found by a searcher. $\pi_s$ can be estimated by placing a known number of marked dead bats in the search area, waiting a few days, then recording how many are found by a searcher.

- Note: there is a temporal aspect to carcass removal (how many days has it been on the ground) that I am ignoring here to keep the problem from getting too complicated.

The data for this problem are made up based on typical numbers for a non-endangered bat species at an Iowa wind farm with a very, very intensive monitoring program. The data are:

- $Y = 23$: the number of unmarked bats (killed by turbines)

There are two carcass detection trials. In each, 50 marked bats were placed in the search area. Searcher efficiency can be assumed to be the same in the two trials. The technicians found:

- $Z_1 = 9$
- $Z_2 = 12$

The search area proportion is known to be:

- $\pi_a = 0.2$

A reasonable model for the searcher trials is: $Z_i \sim Bin(50, \pi_s)$, and a reasonable model for the tubrine mortality is $Y \sim Bin(N, \pi_a, \pi_s)$. At the end of the problem, we will consider a different model for turbine mortality where $Y \sim Pois(N,\pi_a,\pi_s)$.

## (a)

What are the expected values of $Y$, $Z_i$, and $Z_1+Z_2$?

- $E[Y] = \Sigma Y * pdf(Y)$

```{r}

```



# 4.) 