---
title: "Ecostats Homework 2"
author: "Martin Simonson"
date: "October 31, 2019"
output: pdf_document
editor_options: 
  chunk_output_type: console
---



```{r,include=F}
# Front matter
rm(list=ls())  # removes objects from environment

# Function to load and install packages
packages<-function(x, repos="http://cran.r-project.org", ...){
x<-as.character(match.call()[[2]])
if (!require(x,character.only=TRUE)){
install.packages(pkgs=x, repos=repos, ...)
require(x,character.only=TRUE)
}
}

# Setting Working Directory
setwd("C:/Users/martysim/Documents/BMB-COC/STAT534/")

# setting up packages
packages(ggplot2)
packages(RMark)
packages(gtools)
```

# 1.) Deer Mice

These data come from a study of deer mice population in sagebrush steppe in Utah. Individuals were trapped on 5 nights. The usual notation for classical (Otis) closed population models is:

- $t$: The number of trapping occasions
- $n$: number of individuals caught on each trapping occasion (vector of length t)
- $n.$: (ndot) the total number of captures, $n. = \Sigma_{i=1}^t n_i$
- $M$: number of tags in popoulation just prior to occasion _i_, $M_i = \Sigma_{j=1}^{i-1}u_j$ except $M_1 = 0$
- $M.$: (Mdot) $=\Sigma_{i=1}^t M_i$ Note this does not include $M_t+1$
- $M_{t+1}$: Total number of unique individuals seen
- $u$: number of unmarked individuals caught on each occasion (vector of length t)
- $m$: number of marked individuals caught on each occasion (vector of length t)
- $m.$ (mdot) total captures of marked individuals, $m. = \Sigma_{i=1}^t m_i$

Note that $n_i = u_i+m_i$ for all $i$. Summary statistics for the mark-recapture study of deer mice are:

              Trap Night 1     Trap Night 2       Trap Night 3    Trap Night 4    Trap Night 5
----------    --------------   ----------------   -------------   -------------   --------------
$n_i$         14               9                  12              11              10
$u_i$         14               5                  11              7               5
$m_i$         0                4                  1               4               5
$M_i$         0                14                 19              30              37  
----------    -------------   ----------------    -------------   -------------   --------------

and $M_{t+1} = 42$. The Chao and Huggins reading has the summary-statistics version of the log-likelihood function for the $M_t$ model. Dr. Dixon's R function to compute the log likelihood is:

```{r}
lnlMt <- function(param, data) {
  t <- data[1] # see note below
  Mt1 <- data[2]
  n <- data[-c(1:2)]
  N <- param[1] # see note below
  p <- param[-1]
  
  lfactorial(N) - lfactorial(N-Mt1) + sum(n*log(p)) + sum((N-n)*log(1-p))
}
```

'param' is a vector with t+1 parameters: N followed by the t capture probabilities. 'data' is a vector with t+2 values: # capture occasions, Mt+1, followed by t occasion-specific # captured.

## (a)

Using results from fitting model $M_t$, calculate a Wald 95% confidence interval for $\hat{N}$

```{r, echo = FALSE, warning=FALSE}
data<-c(5, 42, 14, 9, 12, 11, 10)
param<-c(42, rep(0.6,5))

fit.1a<-optim(param, lnlMt, method = 'BFGS',data = data, control = list(fnscale = -1), hessian = T)
fit.1a$par[1]


betahat<-fit.1a$par
fit.1a.vc<-solve(-fit.1a$hessian)
fit.1a.se<-sqrt(diag(fit.1a.vc))

betahat.ci<-cbind(
  lower = betahat - qnorm(0.975)*fit.1a.se,
  upper = betahat + qnorm(0.975)*fit.1a.se)
betahat.ci[1,]
```

Our estimate of $\hat{N}= 75.45$, and our 95% confidence interval is bounded between 46.80 and 104.10.

## (b)

Rewrite the log-likelhiood function in terms of $log(N)$. Use log-transformed $N$ to calculate a Wald 95% confidence interval for $N$.

```{r, echo = F, warning=FALSE}

data<- c(5, 42, 14, 9, 12, 11, 10)
param<-c(log(42), rep(0.1,5))

lnlMt2 <- function(param, data) {
  t <- data[1] 
  Mt1 <- data[2]
  n <- data[-c(1:2)]
  logN <- exp(param[1]) 
  p <- param[-1]
  lfactorial(logN) - lfactorial(logN-Mt1) + sum(n*log(p)) + sum((logN-n)*log(1-p))
}


fit.1b<-optim(param, 
              lnlMt2, 
              method = 'BFGS',
              data = data, 
              control = list(fnscale = -1),
              hessian = T)
#fit.1b$par
exp(fit.1b$par[1])

betahat<-fit.1b$par[1]
fit.1b.vc<-solve(-fit.1b$hessian)
fit.1b.se<-sqrt(diag(fit.1b.vc))

betahat.ci<-cbind(
  lower = betahat - qnorm(0.975)*fit.1b.se,
  upper = betahat + qnorm(0.975)*fit.1b.se)
exp(betahat.ci[1,])
```

The estimate for log-transformation yielded an estimate of $\hat{N} = 75.43$ and the 95% confidence interval is bounded between 51.60 and 110.25.


## (c)

Write a profile log-likelihood function for $N$ (so the only parameter is $\hat{N}$, $p$ is computed in your function). Use that model to calculate a 95% profile confidence interval for $\hat{N}$. 

```{r, include = F, warning=FALSE}
# need to re-structure data vector to fit this function?
data<- c(5, 42, 14, 9, 12, 11, 10)
param<-c(75.42819, rep(0.3,5))

lnlM0p <- function(param, data) {
   N <- param[1]
  # overall probability of capture is # seen / N*#times
   p <- data[-c(1:2)]/(N)
  # then call lnlMt with the provided N and calculated p
   lnlMt(c(N,p), data)
  }


# maximize the fit in 1D
optimize(lnlM0p, c(20,120), data=data, maximum=T)
# arguments are the:
#   function to maximize, first argument must be the parameter
#   the interval to search.  Could also be lower=40, upper=100
#   any additional arguments to the function, here the data
#   default is to minimize, setting maximum=T looks for the maximum
# gives you $maximum = location of maximum and $objective = lnl at max
# generate values for the profile likelihood curve


# finding a 95% confidence interval
# approach: want to find X values such that 2*(lnl(mle) - lnl(X)) = 3.84
#  do by finding roots of (lnl(mle) - lnl(X)) - 3.84/2 = 0

# implement by defining a check function to calculate (lnl(X) - lnl(mle)) + 3.84
# that's the negative, but this has the same roots, and matches shape of lnlN

ciM0p <- function(X, mle, data, coverage = 0.95) {
#  X is the argument
#  mle is the estimated parameter
#  coverage is the desired coverage, e.g. 0.95, 
#    used to calculate the Chi-square quantile, e.g. 3.84
#  and data is the capture history matrix

  (lnlM0p(X, data=data) - lnlM0p(mle, data=data)) + qchisq(coverage,1)/2
  }

mleN <- optimize(lnlM0p, c(20,100), data=data, maximum=T)$maximum
mleN

lowerN <- uniroot(ciM0p, c(20, mleN), mle=mleN, data=data)
# first argument is the function to find a root for
# second is the interval to search in
# since ciM0p requires an mle for N and a data set, 
#   need to provide those by name in the call to uniroot

lowerN$root
# $root is the root, the rest is supplemental information

# find upper ci endpoint by searching from mle to something large

upperN <- uniroot(ciM0p, c(mleN, mleN*10), mle=mleN, data=data)
upperN$root
```

```{r, echo = F}
cat('95% ci')
c(lowerN$root, upperN$root)

# and if you don't like fractions of critters, 
#   round lower down and upper up

#c(floor(lowerN$root), ceiling(upperN$root) )

```

The profile log-likelihood for $N$ results in a 95% confidence interval between 54.97 and 118.36.


## (d)

Look at the plots of profile likelihood vs. $N$ and vs. $log(N)$. If you had to use a normal approximation, which is more appropriate? $N \approx normal$ or $log(N) \approx normal$? Briefly explain your choice and include your plot(or plots) of the profile likelihood.

```{r, warning= FALSE}
# profile likelihood function
allN <- 20:120
lnlN<-rep(NA,length(allN))
for(i in 1:length(allN)){
  lnlN[i] <-lnlM0p(allN[i], data)
}
```

```{r, echo = F}
plot.new() # clear previous plots
par(mfrow=c(1,2)) # set frame to show two plots at once, side by side
par(mar=c(3,3,3,3)+0.2, mgp=c(2,0.8,0)) # setting margins, etc

plot(allN,lnlN, main = "Profile likelihood vs. N")

plot(allN,lnlN, main = "Profile likelihood vs. log(N)", log = "x")
```

Although neither plot shows very strong evidence for a normal approximation, the $log(n) \approx normal$ would be better for analysis, due to a more distinct parabola shape.


## (e)

Results from fitting 3 models ($M_0, M_t, M_b$) are:

Model         AIC              $\hat{N}$        s.e.  
----------    --------------   ---------------  -------------
$M_0$         -13.51           75.88            14.77 
$M_t$         -7.05            75.40            14.59  
$M_b$         -11.90           61.65            17.67
----------    -------------    ---------------  -------------

Using AIC weights, compute the model-averaged estimate of $N$ and its standard error, using the Buckland s.e. formula. Derive the AIC weights from AIC column. Variance needed in Buckland formula is the variance($\hat{N}$). Standard deviation is of observations, and standard error is of the estimate. 

```{r, echo = F}
# AIC to objects
M0.AIC<- -13.51
Mt.AIC<- -7.05
Mb.AIC<- -11.90
# assign change in AIC values
M0.Delta.AIC<-1
mt.Delta.AIC<-exp(-6.46/2)
mb.Delta.AIC<-exp(-1.61/2)
# determine sum of delta AIC
AIC.sums<-sum(M0.Delta.AIC,mt.Delta.AIC,mb.Delta.AIC)
# Assign model-specific AIC weights
M0.w<-M0.Delta.AIC/AIC.sums
Mt.w<-mt.Delta.AIC/AIC.sums
Mb.w<-mb.Delta.AIC/AIC.sums
# obtain variance for each model from SE
M0.v<-14.77^2
Mt.v<-14.59^2
Mb.v<-17.67^2
# sum variances
v.sums<-sum(M0.v,Mt.v,Mb.v)
# calculate theta as sum of weight*nhat
theta<-(M0.w*75.88)+(Mt.w*75.40)+(Mb.w*61.65)
theta

# Calculate error of the estimate
SE<- (M0.w*(sqrt(M0.v+(75.88-theta)^2)))+
  (Mt.w*(sqrt(Mt.v+(75.4-theta)^2)))+
  (Mb.w*(sqrt(Mb.v+(61.65-theta)^2)))
SE
```

The model-averaged estimate of $\hat{N} = 71.59$ and the model-averaged $SE = 16.84$.

## (f)

Imagine you had three different studies of the same population. These are conducted by different people at slightly different times, but we will assume that the population remains closed across the three studies (so the true $N$ is the same for all three studies). The study results are:

Study         $\hat{N}$        Var $\hat{N}$  
----------    --------------   --------------
A             145              30         
B             147              30           
C             143              30         
----------    -------------    --------------

The three studies can be assumed to be independent estimates of $N$. If you average the results from these three studies, what is the pooled estimate ($\hat{N}$) and its associated standard error? __Note:__ These three studies are independent, so averaging them is just like calculating a sample mean and its precision. _I am taking this under the assumption that we can caluclate the precision as error around our $\hat{N}$, basically ignoring the Variance column  in the table above._

```{r, echo = F}
Nhat<- mean(145,147,143)
Nhat

study<-c(145,147,143)
error<- sd(study)/sqrt(3)
error
```

The pooled estimate of $\hat{N} = 145$ and its associated standard error is $SE = 1.1547$. The estimate of SE in this method is incorrect, and clearly much lower than the SE from across all three studies.

## (g)

Now imagine the same results were obtained form fitting three models to the results in from Study A. Those results, including model weights, are:

Model         $\hat{N}$        Var $\hat{N}$    Weight  
----------    --------------   ---------------  -------------
A             145              30               1/3
B             147              30               1/3  
C             143              30               1/3
----------    -------------    ---------------  -------------

Compute the model-averaged estimate of $N$ and its standard error (Buckland formula is sufficient).

```{r, echo = F}
MA.w<-1/3
MB.w<-1/3
MC.w<-1/3

MA.v<-30
MB.v<-30
MC.v<-30


theta<-(MA.w*145)+(MB.w*147)+(MC.w*143)
theta

SE<- (MA.w*(sqrt(MA.v+(145-theta)^2)))+
  (MB.w*(sqrt(MB.v+(147-theta)^2)))+
  (MC.w*(sqrt(MC.v+(143-theta)^2)))
SE
```

Our estimate of $\hat{N} = 145$, which is the same as the pooled estimate in (f). The Buckland standard error formula yielded $SE=5.713$. This error is more appropriate than the error obtained from (f).

## (h)

In statistical terms, why are the results from question 1(g) not identical to those from question 1(f)? Note that at least some of the values should be different.

- __Answer:__ The estimate of $\hat{N}$ is the same between question 1(g) and 1(f), but that makes since because the mean of our three estimates is the sum of each estimate divided by three, while the weighted model average method had equal model weights of 1/3, which yielded the same estimate. Our estimates of precision were different, however. This difference is due to the fact that in part 1(f), we are measuring the variance of $\hat{N}$ estimates, ignoring the variance within the models. In 1(g) however, we used the Buckland formula which accounts for the within-model variance and more appropriately provides estimates of precision around $\hat{N}$.

# 2.) Heterogeneity Models

This problem explores models for heterogeneity. The data in _huggins2019.txt_ have capture histories for 97 animals and a measured covariate for each animal. The data are simulated and true population size will be shared by Dr. Dixon later.

## (a)
  
Fit a variety of models, including some that model heterogeneity using a mixture distribution (i.e. the Pledger approach) to the data. What model(s) seem reasonable? Do the data support heterogeneity between individuals? _Note:_ Dr. Dixon has had trouble using the 'HetClosed' for some models, so using the 'FullHet' class. Dr. Dixon will distribute an introductory modeling heterogeneity guide.

```{r, include = F}
library(RMark)
huggins<-import.chdata("huggins2019.txt")
head(huggins)

huggins$X<-as.numeric(as.character(huggins$X))
str(huggins)
```

```{r,include = F}
# models:
run.huggins <- function() {
  f0 <- list(formula=~1)
  f0s<- list(formula = ~1, share = T) # shared probability of capture and recapture
  ft <- list(formula=~time, share = T)
  fT <- list(formula = ~ Time, share = T)
  ftb<- list(formula = ~ time+c, share = T)
  fh<-list(formula=~mixture, share = T) # all 8 models
  fht<-list(formula=~mixture+time, share = T) # hetreogeneity model + time effect
  fbh <- list(formula =~mixture+c, share = T) # c = capture probability
  fbht<-list(formula=~mixture+time+c, share = T)
  
  
  
  m0 <-mark(huggins, model='FullHet', model.parameters = list(p=f0s))
  mt <-mark(huggins, model='FullHet', model.parameters = list(p=ft))
  mT <-mark(huggins, model='FullHet', model.parameters = list(p=fT))
  mb <-mark(huggins, model='FullHet', model.parameters = list(p=f0,c=f0))
  mtb <-mark(huggins, model='FullHet', model.parameters = list(p=ftb, c=f0))
  mh <-mark(huggins, model='FullHet', model.parameters = list(p=fh))
  mht<-mark(huggins,model='FullHet', model.parameters=list(p=fht))
  mbh<-mark(huggins,model='FullHet', model.parameters=list(p=fbh,c=f0))
  mbht<-mark(huggins,model='FullHet',model.parameters=list(p=fbht,c=f0))
  
  return(collect.models())
}

huggins.results<-run.huggins()
```

```{r, warning= FALSE}
model.table(huggins.results,model.name=F)
```

- __Answer:__ The models that seem most reasonable (4 lowest AIC values) are the mixture models that include heterogeneity. Therefore, I would conclude that the data support heterogeneity models. 


## (b)

Fit a variety of models to the data, including some that model heterogenity as a function of the covariate X (i.e. the Huggins approach). What model(s) seem reasonable? Do the data support heterogeneity between individuals?

```{r, include = F}
run.huggins2 <- function() {
  f0 <- list(formula=~1)
  f0s<- list(formula = ~1, share = TRUE) # shared probability of capture and recapture
  ft <- list(formula=~time, share = T)
  fT <- list(formula = ~ Time, share = T)
  ftb<- list(formula = ~ time+c, share = T)
  fc<-list(formula=~X, share = T) # all 8 models
  fct<-list(formula=~X+time, share = T) # hetreogeneity model + time effect
  fbc <- list(formula =~X+c, share = T) # c = capture probability
  fbct<-list(formula=~X+time+c, share = T)
  
  
  
  m0 <-mark(huggins, model='Huggins', model.parameters = list(p=f0s))
  mt <-mark(huggins, model='Huggins', model.parameters = list(p=ft))
  mT <-mark(huggins, model='Huggins', model.parameters = list(p=fT))
  mb <-mark(huggins, model='Huggins', model.parameters = list(p=f0,c=f0))
  mtb <-mark(huggins, model='Huggins', model.parameters = list(p=ftb, c=f0))
  mc <-mark(huggins, model='Huggins', model.parameters = list(p=fc))
  mct<-mark(huggins,model='Huggins', model.parameters=list(p=fct))
  mbc<-mark(huggins,model='Huggins', model.parameters=list(p=fbc,c=f0))
  mbct<-mark(huggins,model='Huggins',model.parameters=list(p=fbct,c=f0))
  
  return(collect.models())
}

huggins.models2<-run.huggins2()
```

```{r}
model.table(huggins.models2,model.name=F)
```

- __Answer:__ The four top models all included heterogeneity as modeled by the covariate $X$, and therefore I would conclude the data support models with heterogeneity.

## (c)

How might you evaluate which of these two approaches is more reasonable for these data? _Note:_ This is a "think about what you have available" question. Likelihood __cannot__ be used because the Pledger and Huggins approaches are based on different data sets.

- __Answer Part 1:__ We do not know what the covariate $X$ is, however, the fact that it was collected usually means it is an attribute that varies among individuals. Further, this covariate may likely contribute to the capture probability of our study organism (e.g., the size of a fish is correlated with is susceptibility to electrofishing). Therefore, I would conclude that the Huggins approach is more appropriate for these data. 

- __Answer Part 2:__ After conferring with other students in class, we discussed comparing the estimates of $\hat{N}$ and their associated standard error. The Pledger models had a lower population estimate and lower standard error (and consequently a narrower confidence interval). For this reason the Pledger models seem more reasonable, but the confidence intervals for both estimates overlap and it is difficult to say if the population estimates from both models are different.

- __FINAL ANSWER:__ It all depnds on what type of organism this is, and if the covariate $X$ is exptected to be reasonably related to capture probabilities. Without that knowledge, I will commit to my first answer to this question (Huggins is better).

## (d)

The annual report needs to make a statement about the number of individuals in this population. This will be read by the general public and legislators, so it needs to be succinct. What conclusions can be made?

```{r}
huggins.results$mh$results$derived
huggins.models2$mc$results$derived
```


- __Answer:__ The top models from both approaches differ in estimate of $\hat{N}$ by about 20 individuals. The Pledger approach had lower associated error, however, I am inclined to stand by my final answer to part (c). Therefore, my statement would be: _"The estimated pouplation size is approximately 132 individuals, with a 95% confidence interval between about 111 and 184 individuals."_

# 3.) Newts

This is a “major data question”. The data in newt.txt are from a study to estimate the number of an adult rare amphibian resident in an area soon to be developed. Adults can be individually identified by the pattern of spots on their belly. Individuals were caught on 12 nights, identified and sexed. The population can be assumed closed over the 12 capture occasions. The data in newtB.txt are the capture histories and sex (1 or 2) for each individual.

Your goal is to provide an estimate of the number of newts in the population. At a minimum, you need to provide an estimate and standard error. A confidence interval would be nice.

_Notes:_ You should consider at least some models that include heterogeneity (e.g., between sexes and/or between individuals). I suggest you avoid model Mtb (time + behavior dependent capture probabilities with time as a categorical factor) because the population size is not identifiable in that model (at least for these data). A model with linear effects of time may be reasonable.

## Answer:

__Methods:__

We estimated newt abundance in two ways. In both approaches, the population was assumed to be closed to births, deaths, immigration and emigration over the entire samping period of 12 capture occasions, and marks were assumed to be individually unique based on spot pattern on the newts' underside. Therefore, marks could not be 'lost' and the assumption that tagging does not affect survival did not apply. Newt gender was identified and coded as either 1 or 2 in the capture history.

The first approach to estimate newt abundance did not use gender as a grouping variable, and as such the models were isolated from models that were grouped by gender. This is due to the fact that different data sets were used with and without gender, and therefore the models are not nested and AIC model evaluation is not appropriate for non-nested models. The three models run for estimating newt abundance without grouping for gender were the null model (denoted _m0_, where capture probability is constant), the time-based model (denoted _mt_, where capture probability varies by capture occasion), and the linear time model (denoted _mT_, where capture probability is a linear function of capture occasion). The second approach to estimate newt abundance grouped the species by gender, thus resulting in two estimates of abundance (one for each gender). The same set of three models ($m0, mt, mT$) were run in the second approach.

In both cases, models were ranced according to Aikike's Information Criterion corrected for small sample size (AICc) and models were run in the R programming language using RStudio and RMark. RMark is a package for R that calls the GUI Program MARK to compute and derive results, but in a faster and more efficient way than Program MARK alone. Paramaters of $\hat{N}$ with associated standard error and 95% confidence intervals were derived from RMark model outputs. 

__Results:__

For both approaches, the $mt$ model was ranked highest, indicating an observed effect of different capture probabilities during each sample occasion. The derived results for both approaches yielded abundance estimates (e.g., $\hat{N}$) that were much closer to the lower end of the 95% confidence interval, which is likely a function of the logit transformation ocurring in each model. The results for the first approach are:

```{r, include = F}
library(RMark)
newt<-import.chdata('newtB.txt', field.types = c('n','f'))
head(newt)
```

```{r, include = F}
## No groups ##

run.newt<-function(){
  f0<-list(formula= ~1)
  f0s<-list(formula=~1, share=TRUE)
  ft<- list(formula=~time, share=TRUE)
  fT<- list(formula=~Time, share=TRUE)
  
  m0<-mark(newt, model = "Closed", model.parameters = list(p=f0s,f0=f0), output = F)
  mt<-mark(newt, model='Closed',  model.parameters= list(p=ft, f0=f0), output = F)
  mT<-mark(newt, model = 'Closed', model.parameters =list(p=fT, f0=f0), output=F)
  
  return(collect.models())
}

newt.model<-run.newt()
model.table(newt.model, model.name = F)
```

```{r,}
# mt is top model
newt.model$mt$results$derived
```

For the set of three models run without adding an effect of gender, the model with time-dependent capture probability had the lowest AICc value and lowest deviance. The other two models tested (linear time effect, 25 AICc units difference; null model, 101 AICc units difference) did not perform as well despite having fewer parameters estimated. The top model yielded an estimate of $\hat{N} = 110$ and a 95% confidence limit bounded between 109 and 117. The results for the second approach are:

```{r, include = F}
## Groups ##
run.newtb<-function(){
  f0<-list(formula= ~1)
  fs<-list(formula=~sex)
  f0s<-list(formula=~1, share=TRUE)
  ft<- list(formula=~time, share=TRUE)
  fT<- list(formula=~Time, share=TRUE)
 
  m0<-mark(newt, model = "Closed", model.parameters = list(p=f0s,f0=fs), groups=c('sex'), output = F)
  mt<-mark(newt, model='Closed',  model.parameters= list(p=ft, f0=fs), groups=c('sex'), output = F)
  mT<-mark(newt, model = 'Closed', model.parameters =list(p=fT, f0=fs), groups=c('sex'), output=F)

  return(collect.models())
}

newtb.model<-run.newtb()
model.table(newtb.model, model.name=F)
```

```{r,}
# mt is still top model
newtb.model$mt$results$derived
```

For the set of  3 models run where data was grouped by gender, the model with time-dependent capture probability had the lowest AICc value and lowest deviance. The other two models tested (linear time effect, 24 AICc units difference; null model, 101 AICc units difference) did not perform as well despite having fewer parameters estimated. The top model yielded an abundance estimate for gender 1 of $\hat{N_1} = 59$ with a 95% confidence interval between 58 and 65, and the abundance estimate for gender 2 was $\hat{N_2} = 51$ with a 95% confidence interval between 50 and 57. The sum of both abundance estimates in the second (grouped) approach equalled the single abundance estimate in the first (ungrouped) approach. 

