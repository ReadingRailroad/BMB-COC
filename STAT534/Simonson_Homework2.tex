\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Ecostats Homework 2},
            pdfauthor={Martin Simonson},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\usepackage{longtable,booktabs}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{Ecostats Homework 2}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{Martin Simonson}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
      \predate{\centering\large\emph}
  \postdate{\par}
    \date{October 18, 2019}


\begin{document}
\maketitle

\section{1.) Deer Mice}\label{deer-mice}

These data come from a study of deer mice population in sagebrush steppe
in Utah. Individuals were trapped on 5 nights. The usual notation for
classical (Otis) closed population models is:

\begin{itemize}
\tightlist
\item
  \(t\): The number of trapping occasions
\item
  \(n\): number of individuals caught on each trapping occasion (vector
  of length t)
\item
  \(n.\): (ndot) the total number of captures,
  \(n. = \Sigma_{i=1}^t n_i\)
\item
  \(M\): number of tags in popoulation just prior to occasion \emph{i},
  \(M_i = \Sigma_{j=1}^{i-1}u_j\) except \(M_1 = 0\)
\item
  \(M.\): (Mdot) \(=\Sigma_{i=1}^t M_i\) Note this does not include
  \(M_t+1\)
\item
  \(M_{t+1}\): Total number of unique individuals seen
\item
  \(u\): number of unmarked individuals caught on each occasion (vector
  of length t)
\item
  \(m\): number of marked individuals caught on each occasion (vector of
  length t)
\item
  \(m.\) (mdot) total captures of marked individuals,
  \(m. = \Sigma_{i=1}^t m_i\)
\end{itemize}

Note that \(n_i = u_i+m_i\) for all \(i\). Summary statistics for the
mark-recapture study of deer mice are:

\begin{longtable}[]{@{}llllll@{}}
\toprule
& Trap Night 1 & Trap Night 2 & Trap Night 3 & Trap Night 4 & Trap Night
5\tabularnewline
\midrule
\endhead
\(n_i\) & 14 & 9 & 12 & 11 & 10\tabularnewline
\(u_i\) & 14 & 5 & 11 & 7 & 5\tabularnewline
\(m_i\) & 0 & 4 & 1 & 4 & 5\tabularnewline
\(M_i\) & 0 & 14 & 19 & 30 & 37\tabularnewline
\bottomrule
\end{longtable}

and \(M_{t+1} = 42\). The Chao and Huggins reading has the
summary-statistics version of the log-likelihood function for the
\(M_t\) model. Dr.~Dixon's R function to compute the log likelihood is:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lnlMt <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(param, data) \{}
\NormalTok{  t <-}\StringTok{ }\NormalTok{data[}\DecValTok{1}\NormalTok{] }\CommentTok{# see note below}
\NormalTok{  Mt1 <-}\StringTok{ }\NormalTok{data[}\DecValTok{2}\NormalTok{]}
\NormalTok{  n <-}\StringTok{ }\NormalTok{data[}\OperatorTok{-}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{2}\NormalTok{)]}
\NormalTok{  N <-}\StringTok{ }\NormalTok{param[}\DecValTok{1}\NormalTok{] }\CommentTok{# see note below}
\NormalTok{  p <-}\StringTok{ }\NormalTok{param[}\OperatorTok{-}\DecValTok{1}\NormalTok{]}
  
  \KeywordTok{lfactorial}\NormalTok{(N)}\OperatorTok{-}\KeywordTok{lfactorial}\NormalTok{(N}\OperatorTok{-}\NormalTok{Mt1) }\OperatorTok{+}\StringTok{ }\KeywordTok{sum}\NormalTok{(N}\OperatorTok{*}\KeywordTok{log}\NormalTok{(p)) }\OperatorTok{+}\StringTok{ }\KeywordTok{sum}\NormalTok{((N}\OperatorTok{-}\NormalTok{n)}\OperatorTok{*}\KeywordTok{log}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\NormalTok{p))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

`param' is a vector with t+1 parameters: N followed by the t capture
probabilities. `data' is a vector with t+2 values: \# capture occasions,
Mt+1, followed by t occasion-specific \# captured.

\subsection{(a)}\label{a}

Using results from fitting model \(M_t\), calculate a Wald 95\%
confidence interval for \(\hat{N}\)

\subsection{(b)}\label{b}

Rewrite the log-likelhiood function in terms of \(log(N)\). Use
log-transformed \(N\) to calculate a Wald 95\% confidence interval for
\(N\).

\subsection{(c)}\label{c}

Write a profile log-likelihood function for \(N\) (so the only parameter
is \(N\), \(p\) is computed in your function). Use that model to
calculate a 95\% profile confidence interval for \(\hat{N}\).

\subsection{(d)}\label{d}

Look at the plots of profile loikelihood vs. \(N\) and vs. \(log(N)\).
If you had to use a normal approximation, which is more appropriate?
\(N \approx normal\) or \(log(N) \approx normal\)? Briefly explain your
choice and include your plot(or plots) of the profile likelihood.

\subsection{(e)}\label{e}

Results from fitting 3 models (\(M_0, M_t, M_b\)) are:

\begin{longtable}[]{@{}llll@{}}
\toprule
Model & AIC & \(\hat{N}\) & s.e.\tabularnewline
\midrule
\endhead
\(M_0\) & -13.51 & 75.88 & 14.77\tabularnewline
\(M_t\) & -7.05 & 75.40 & 14.59\tabularnewline
\(M_b\) & -11.90 & 61.65 & 17.67\tabularnewline
\bottomrule
\end{longtable}

Using AIC weights, compute the model-averaged estimate of \(N\) and its
standard error, using the Buckland s.e. formula.

\subsection{(f)}\label{f}

Imagine you had three different studies of the same population. These
are conducted by different people at slightly different times, but we
will assume that the population remains closed across the three studies
(so the true \(N\) is the same for all three studies). The study results
are:

\begin{longtable}[]{@{}lll@{}}
\toprule
Study & \(\hat{N}\) & Var \(\hat{N}\)\tabularnewline
\midrule
\endhead
A & 145 & 30\tabularnewline
B & 147 & 30\tabularnewline
C & 143 & 30\tabularnewline
\bottomrule
\end{longtable}

The three studeis can be assumed to be independent estimates of \(N\).
If you average the results from these three studies, what is the pooled
estimate (\(\hat{N}\)) and its associated standard error? \emph{Note:}
These three studies are independent, so averaging them is just like
calculating a sample mean and its precision.

\subsection{(g)}\label{g}

Now imagine the same results were obtained form fitting three models to
the results in from Study A. Those results, including model weights,
are:

\begin{longtable}[]{@{}llll@{}}
\toprule
Model & \(\hat{N}\) & Var \(\hat{N}\) & Weight\tabularnewline
\midrule
\endhead
A & 145 & 30 & 1/3\tabularnewline
B & 147 & 30 & 1/3\tabularnewline
C & 143 & 30 & 1/3\tabularnewline
\bottomrule
\end{longtable}

Compute the model-averaged estimate of \(N\) and its standard error
(Buckland formula is sufficient).

\subsection{(h)}\label{h}

In statistical terms, why are the results from question 1(g) not
identical to those from question 1(f)? Note that at least some of the
values should be different.

\begin{itemize}
\tightlist
\item
  \textbf{Answer:}
\end{itemize}

\section{2.) Heterogeneity Models}\label{heterogeneity-models}

This problem explores models for heterogeneity. The data in
\emph{huggins2019.txt} have capture histories for 97 animals and a
measured covariate for each animal. The data are simulated and true
population size will be shared by Dr.~Dixon later.

\subsection{(a)}\label{a-1}

Fit a variety of models including some that model heterogeneity using a
mixture distribution (i.e.~the Pledger approach) to the data. What
model(s) seem reasonable? Do the data support heterogeneity between
individuals? \emph{Note:} Dr.~Dixon has ahad trouble using the
`HetClosed' for some models, so using the `HetFull' class. Dr.~Dixon
will distribute an Intro to modeling heterogeneity guide.

\subsection{(b)}\label{b-1}

Fit a variety of models to the data, including some that model
heterogenity as a function of the covariate X (i.e.~the Huggins
approach). What model(s) seem reasonable? Do the data support
heterogeneity between individuals?

\subsection{(c)}\label{c-1}

How might you evaluate which of these two approaches is more reasonable
for these data? \emph{Note:} This is a ``think about what you have
available'' question. Likelihood \textbf{cannot} be used because the
Pledger and Huggins approaches are based on different data sets.

\begin{itemize}
\tightlist
\item
  \textbf{Answer:}
\end{itemize}

\subsection{(d)}\label{d-1}

The annual report needs to make a statement about the number of
individuals in this population. This will be read by the general public
and legislators, so it needs to be succinct. What conclusions can be
made?

\begin{itemize}
\tightlist
\item
  \textbf{Answer:}
\end{itemize}

\section{3.) Bats}\label{bats}

This problem is a simplified version of something in regular use. Wind
turbines kill birds and bats. The Fish and Wildlife Service cares (a
lot) when those are endangered or threatened bats (because of the
Endangered Species Act) or eagles (because of the Bald and Golden Eagle
Protection Act). Hence, owners of wind turbine farms are required to
estimate the number of killed bats and killed eagles. Eagle kill is
mostly in the winter and an eagle carcass on snow is pretty easy to
spot. Bat mortality is harder to estimate. Bat kill is mostly late
summer and early fall. Dead bats are hard to spot; they are small, dark
brown critters that fall on bare ground, grass/prairie, or in the middle
of a crop field. The data to estimate bat kill are collected by trained
technicians who search the ground around each turbine and identify each
carcass they find. They search every week and sometimes more frequently.
The number killed is larger than the number seen for three different
reasons:

\begin{itemize}
\tightlist
\item
  only a portion of the area is searched
\item
  scavengers, e.g.~coyotes or raccoons, remove a carcass before the
  technician looks for it
\item
  the searcher doesn't see a carcass that is in the search area and not
  scavenged.
\end{itemize}

The portion of area searched, \(\pi_a\), is a known constant. The
searcher efficiency and scavenger removal rate are estimated by placing
a known number of marked dead bats on the ground and seeing how many are
found by the technician. In actual use, the searcher efficiency and
scavenger removal rate are estimated by two different studies. I am
simplifying this problem by combining the two rates into a single
probability: \(\pi_s\) is the probability that a carcass falling in the
searched area is found by a searcher. \(\pi_s\) can be estimated by
placing a known number of marked dead bats in the search area, waiting a
few days, then recording how many are found by a searcher.

\begin{itemize}
\tightlist
\item
  Note: there is a temporal aspect to carcass removal (how many days has
  it been on the ground) that I am ignoring here to keep the problem
  from getting too complicated.
\end{itemize}

The data for this problem are made up based on typical numbers for a
non-endangered bat species at an Iowa wind farm with a very, very
intensive monitoring program. The data are:

\begin{itemize}
\tightlist
\item
  \(Y = 23\): the number of unmarked bats (killed by turbines)
\end{itemize}

There are two carcass detection trials. In each, 50 marked bats were
placed in the search area. Searcher efficiency can be assumed to be the
same in the two trials. The technicians found:

\begin{itemize}
\tightlist
\item
  \(Z_1 = 9\)
\item
  \(Z_2 = 12\)
\end{itemize}

The search area proportion is known to be:

\begin{itemize}
\tightlist
\item
  \(\pi_a = 0.2\)
\end{itemize}

A reasonable model for the searcher trials is:

\[
Z_i \sim Bin(50, \pi_s)
\]

A reasonable model for the tubrine mortality is

\[
Y \sim Bin(N, \pi_a, \pi_s)
\]


\end{document}
